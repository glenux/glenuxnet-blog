# R√©duire la latence

## Apple M1, MacOS et la QoS

R√©cent article sur Hackernews √† propos de la QoS d'Apple sur les processeurs M1)

FIXME: date ? lien ?

* Super int√©ressant
* Envie de faire pareil sur linux
* Tout en sachant que le CPU n'est pas le m√™me et que ... √ßa n'aura pas le m√™me impact sur la partie performance.

Objectif : r√©duire la latence de Linux sur un Intel Core i5

Nota-Bene: √©videmment, sans le processeur M1 (qui est asym√©trique en terme d'√©conomie d'√©nergie / puissance) √ßa a peu de sens en terme de performances... puisqu'on se coupe de la moiti√© du processeur, en revanche en terme de latence les r√©sultats sont nettement perceptibles.

## La bande passante et la latence

* Une sombre histoire de scheduling
* Probleme classique de l'allocation des ressources (scheduling, realtime, etc.)
* Longue histoire au niveau Linux
* diff√©rents schedulers qui cherchent √† r√©soudre le probleme avec une strat√©gie "g√©n√©rique"
* mais...  √ßa d√©pend aussi du mat√©riel
* mais... √ßa d√©pend aussi de l'usage
* des fois il faut "aider" le scheduler √† la main (selon ce qu'on cherche √† faire)

## Vue d'ensemble

* on cherche √† d√©placer les processus utilisateur

* on cherche √† d√©placer les processus syst√®me

* on cherche √† d√©placer les processus kernel
  
   * les worker threads
   * la gestion des IRQ
   * les autres kernel threads

* on veut mesurer / comparer les performances
  
   * bande passante (temps minimum de calcul pour une appli utlisateur)
   * latence

## D√©placer les processus utilisateur

‚úÖ D√©placer les proc. user sur CPU 2-3
.... via systemd user.slice + CPUAffinity

‚úÖ D√©placer les proc. systeme sur CPU 0-1 
.... via system system.conf + CPUAffinity

‚úÖ D√©placer la gestion du desktop (KDE/plasma) sur CPU 0-1
.... via systemd --user + services + CPUAffinity + delegate des cpusets

‚úÖ D√©placer les kernels workers threads sur CPU 0-1 
.... avec des `echo .. > /sys/devices/virtual/workqueue/*/cpumask`

‚úÖ D√©placer la gestion des IRQ sur CPU 0-1
.... avec des `echo .. > /proc/irq/*/smp_affinity_list`
.... puis gestion des IRQ en tant que kernel theads au lieu de IRQ context (avec l'option kernel `threadirqs`)

‚ùå D√©placer les autres kernels threads sur CPU 0-1 
.... cpuset ne fonctionne plus avec les cgroups2 
.... cgget/cgset n'accepte pas les m√™mes options üò±

Une id√©e ?

Ping Jean-Baptiste Yun√®s, Fran√ßois Armand, Roland Laur√®s, J√©r√¥me Arzel

> Quelle latence veux tu r√©duire ? J'imagine qu'il s'agit de la r√©activit√© globale du syst√®me sur un PC utilisateur ? Donc interactions utilisateur, et probablement attente des requ√™tes r√©seau ? 

> Quand je trouve que mon syst√®me ressemble √† un paresseux, en g√©n√©ral, j'attends un retour r√©seau... Du coup les petites astuces locales risquent d'√™tre peu significatives ?

Pour l'instant j'ai observ√© la quantit√© d'IO g√©r√©e par CPU et la quantit√© de context-switch.

En effet, les IO visibles / lentes sont celles les disques (pas SSD) et celles du r√©seau

FIXME: v√©rifier ?

> En d√©but d'ann√©e, j'ai jou√© avec des cgroups v1 pour optimiser l'empilement de VM sur des serveurs. Vu la v√©tust√© des syst√®mes h√¥tes install√©s, pas pu jouer avec les cgroups V2 (sauf sur mon PC).

Effectivement les cgroups V2 ont une granularit√© plus fine au niveau de /sys/ mais je n'ai pas eu le courage de lire toute la doc kernel √† ce sujet... et les outils & techniques mentionn√©s dans toutes autres docs que j'ai lu concernent les cgroupsv1. 

En effet, il va falloir faire des ioctl ou aller jouer avec fichiers de /sys

J'essayais d'esquiver, mais crois que je vais devoir RTFM du coup :)

FIXME: quelle est la diff√©rence entre cgroups v1 et v2 ?

> Est-ce que tu ne peux pas faire des echo dans les fichiers cgroup v2 pour contourner tes pbs de cgset ?
> Les cgroups V2 ont des "prises" pour les I/O latency... T'as essay√© ?

Pas encore :)

> Comme tu dis, du coup tes CPU 0-1 d√©di√©s au syst√®me vont pas avoir besoin de refroidissement.

FIXME: comment est fait le refroidissmeent des CPU sous linux ?

> T'as regard√© comment les CPU 0-1 √©taient "mapp√©s" sur les cores ? Souvent la num√©rotation lin√©aire des CPU est mapp√©e de mani√®re discontinue sur les sockets/core... Du coup, il serait peut-√™tre mieux de focaliser le kernel sur 0 et 2 ?

Je me suis fait la remarque, mais je n'ai pas regard√© les d√©tails de ce cot√© l√†.
J'ai v√©rifi√© les question de NUMA / distance √† la m√©moire. Ici c'est √©gal pour tous les CPU.

FIXME: comment savoir comment les CPU sont mapp√©s sur les cores ?

> √áa me rappelle les tentatives de Vincent Minet (un de tes successeurs √† P7) sur un TP de benchmark de changement de contexte. Il avait isol√© son application de benchmark, sur des CPU et contenu les IRQ sur d'autres... Si √ßa se trouve, j'ai peut-√™tre encore son compte-rendu de TP dans mes archives. Au prochain confinement, je fouillerai. Et malgr√© tout le r√©sultat n'√©tait pas constant, il y avait des perturbations dont nous n'avons pas trouv√© l'origine... A l'√©poque le noyau Linux n'avait pas tous les outils de configuration dont on dispose actuellement, la situation s'est probablement am√©lior√©e.

> Vu que t'as essay√©, t'as des mesures avant / apr√®s ?

FIXME: comment faire des mesures sur la latence

FIXME: comment mesurer o√π sont distribu√©es les IO ?

FIXME: commenr mesurer le temps processus sur chaque CPU

## R√©f√©rences

* [Troubleshooting High I/O Wait in Linux](https://bencane.com/2012/08/06/troubleshooting-high-io-wait-in-linux/)
* https://haydenjames.io/linux-server-performance-disk-io-slowing-application/
* [Throttle per process I/O with max limit](https://unix.stackexchange.com/questions/48138/how-to-throttle-per-process-i-o-to-a-max-limit)
   - cgroup + blkio controller
* [Using cgroups to limit I/O](https://andrestc.com/post/cgroups-io/)

Context switching

* https://unix.stackexchange.com/questions/466374/how-to-change-linux-context-switch-frequency
* https://unix.stackexchange.com/questions/466722/how-to-change-the-length-of-time-slices-used-by-the-linux-cpu-scheduler/466723#466723

## Monitoring

* https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/

## Notes

* Pr√©ciser que √ßa d√©pend du IO scheduler (elevator=bfq / elevator=noop / etc.)
* 

FIXME: il se passe quoi avec le reatime ? 
